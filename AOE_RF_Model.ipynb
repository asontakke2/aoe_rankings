{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age of Empires 2 Player Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is used to rank invidividual players in team games. This model will allow us to better balance teams by calculating the probability that team wins before we actually play.\n",
    "\n",
    "Disclaimer: I am not a data scientist. Just a guy with too much free time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo:\n",
    "- Create test cases\n",
    "- Load data from Google Sheet instead of local CSV\n",
    "- Determine what EDA should be done\n",
    "- Fix GridSearchCV to LogisticRegression import\n",
    "- Explore adding a time component to factor in player improvement\n",
    "- Determine how to better input data for predicting\n",
    "- Build other classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shaq</th>\n",
       "      <th>Gray</th>\n",
       "      <th>Rushi</th>\n",
       "      <th>Marc</th>\n",
       "      <th>Peter</th>\n",
       "      <th>Pat</th>\n",
       "      <th>Sam</th>\n",
       "      <th>Ori</th>\n",
       "      <th>Vic</th>\n",
       "      <th>Ardy</th>\n",
       "      <th>Chad</th>\n",
       "      <th>Pat_Jr</th>\n",
       "      <th>Pat_Jr_Jr</th>\n",
       "      <th>Matt_M</th>\n",
       "      <th>Ben</th>\n",
       "      <th>Mikey</th>\n",
       "      <th>Evan</th>\n",
       "      <th>Medium_AI</th>\n",
       "      <th>Extra_Team</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Shaq  Gray  Rushi  Marc  Peter  Pat  Sam  Ori  Vic  Ardy  Chad  Pat_Jr  \\\n",
       "0     1     0     -1    -1      1    0   -1    0    0     0     0       0   \n",
       "1     1     0     -1     0     -1    1   -1    1    0     0     0       0   \n",
       "\n",
       "   Pat_Jr_Jr  Matt_M  Ben  Mikey  Evan  Medium_AI  Extra_Team  Outcome  \n",
       "0          0       0    0      0     0          0          -1       -1  \n",
       "1          0       0    0      0     0          0           0       -1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sample_data.csv\")\n",
    "\n",
    "# Designate all columns that are not `Outcome` as features and `Outcome` as target\n",
    "X = df.loc[:, df.columns != 'Outcome']\n",
    "y = df.Outcome\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data\n",
    "This is where I should explore data. I haven't done any EDA since I created this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data\n",
    "Normally, I would split the data into a training set and validation set. The validation set is for checking the accuracy of the best tuned model that results from cross-validation. HOWEVER, we are working with a really small dataset. Rather than hold out data for validation, we will assess the performance of the model through the out of sample cross validation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double data\n",
    "Since assigning teams is random, we want to ensure that the dataset is balanced. For example, when I record data, I generally always put myself as the home team (code as `1`). We mitigate this by not having an intercept term in our model. To be safe, we will still double the dataset by inverting all the records and concatenating to the orginal dataset.\n",
    "\n",
    "Doubling happens after splitting. Therefore we would need to double the training and validation sets. We use helper functions for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_dataframe(original_dataframe):\n",
    "    \"\"\"Inverts the dataframe by simply multiplying all values by -1.\n",
    "\n",
    "    Args:\n",
    "        original_dataframe (df): The dataframe to be inverted.\n",
    "\n",
    "    Returns:\n",
    "        inverted_dataframe (df): The inverted dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    inverted_dataframe = original_dataframe.multiply(-1)\n",
    "    return inverted_dataframe\n",
    "\n",
    "\n",
    "def combine_dataframe(first_dataframe, second_dataframe):\n",
    "    \"\"\"Combines the dataframes. Assumes that both dataframes have the same columns\n",
    "\n",
    "    Args:\n",
    "        first_dataframe (df): The first dataframe to be combined.\n",
    "        second_dataframe (df): The second dataframe to be combined.\n",
    "\n",
    "    Returns:\n",
    "        combined_dataframe (df): The combined dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    combined_dataframe = pd.concat([first_dataframe, second_dataframe])\n",
    "    return combined_dataframe\n",
    "\n",
    "\n",
    "def invert_and_combine(original_dataframe):\n",
    "    \"\"\"Inverts and combines the dataframes. Assumes that both dataframes have the same columns\n",
    "\n",
    "    Args:\n",
    "        original_dataframe (df): The dataframe to be inverted and combined with the original.\n",
    "\n",
    "    Returns:\n",
    "        new_dataframe (df): The combined dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    inverted_dataframe = invert_dataframe(original_dataframe)\n",
    "    new_dataframe = combine_dataframe(original_dataframe, inverted_dataframe)\n",
    "    return new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = invert_and_combine(X)\n",
    "y = invert_and_combine(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "We will use 3 folds cross validation and GridSearch to determine the optimal hyper parameters for the random forest. We will first use randomized search to narrow down the hyperparameters to grid search over. [Credit for this code and approach](https://towardsdatascience.com/random-forest-in-python-24d0893d51c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model according to random search: 0.54 using {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 70, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, \n",
    "                               random_state=0, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X,y)\n",
    "\n",
    "print(\"Best model according to random search: {0} using {1}\".format(\n",
    "    round(rf_random.best_score_, 2), rf_random.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation - Grid Search\n",
    "Now that we have narrowed down the parameters, we can run a more targeted Grid Search. Since this is a brute force method, it takes a while to run on my quad core 16GB laptop. We will use parameters that are close to the best random search parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'n_estimators': [100, 200, 300, 400, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 466 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:   45.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model according to grid search: 0.54 using {'bootstrap': False, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "#rf = RandomForestClassifier()\n",
    "grid = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 1, scoring='accuracy')\n",
    "grid_models = grid.fit(X, y)\n",
    "\n",
    "print(\"Best model according to grid search: {0} using {1}\".format(\n",
    "    round(grid_models.best_score_, 2), grid_models.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in accuracy between grid and random: 0.0\n"
     ]
    }
   ],
   "source": [
    "change_in_accuracy = grid_models.best_score_ - rf_random.best_score_\n",
    "\n",
    "print(\"Difference in accuracy between grid and random: {0}\".format(round(change_in_accuracy), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model from grid search only has a 54% accuracy on the test folds. This model is barely better than guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create final model\n",
    "We will re-fit the best performing random forest to the whole data set. We do not have much confidence in this model because of how poorly it performed in cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_params = grid_models.cv_results_['params'][grid_models.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: must be a cleaner way to import GridSearchCV into RandomForestClassifier\n",
    "final_model_with_all_data = RandomForestClassifier(bootstrap=final_model_params['bootstrap'],\n",
    "                                               max_depth=final_model_params['max_depth'],\n",
    "                                               max_features=final_model_params['max_features'],\n",
    "                                               min_samples_leaf=final_model_params['min_samples_leaf'],\n",
    "                                                  n_estimators=final_model_params['n_estimators'])\n",
    "\n",
    "final_model_with_all_data = final_model_with_all_data.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now check the feature importances. This basically tells us what features are most important when predicting the game outcome (either win or loss.) We could build a slimmed down model using only the variables with high importance. While there is an order to the importance, the actual coefficients are not very high (max coefficient would be 1). In general, most of the features have similar importance and it is not really worth creating a new model with the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Rushi                Importance: 0.1\n",
      "Feature: Marc                 Importance: 0.1\n",
      "Feature: Peter                Importance: 0.1\n",
      "Feature: Gray                 Importance: 0.08\n",
      "Feature: Pat                  Importance: 0.08\n",
      "Feature: Sam                  Importance: 0.08\n",
      "Feature: Ori                  Importance: 0.08\n",
      "Feature: Extra_Team           Importance: 0.07\n",
      "Feature: Shaq                 Importance: 0.05\n",
      "Feature: Vic                  Importance: 0.05\n",
      "Feature: Ardy                 Importance: 0.05\n",
      "Feature: Matt_M               Importance: 0.03\n",
      "Feature: Medium_AI            Importance: 0.03\n",
      "Feature: Chad                 Importance: 0.02\n",
      "Feature: Pat_Jr_Jr            Importance: 0.02\n",
      "Feature: Ben                  Importance: 0.02\n",
      "Feature: Evan                 Importance: 0.02\n",
      "Feature: Pat_Jr               Importance: 0.01\n",
      "Feature: Mikey                Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "importances = list(final_model_with_all_data.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_list = list(X.columns)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "[print('Feature: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Ultimately, we want to use this model to determine the probability of a game. Each value in the array corresponds to a person. For example, the first number is Shaq, the second number is Gray, etc.\n",
    "\n",
    "However, there isn't much to takeaway from this model. Its accuracy in cross validation was barely better than guessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have modeled the probability that Marc (-1) beats Rushi (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that Marc beats Rushi is 29.5%\n"
     ]
    }
   ],
   "source": [
    "result = final_model_with_all_data.predict_proba(\n",
    "    [[0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "print(\"The probability that Marc beats Rushi is {0}%\".format(round(result[0][0]*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have modeled the probability that Shaq (-1) beats Gray (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that Shaq beats Gray is 0.0%\n"
     ]
    }
   ],
   "source": [
    "result = final_model_with_all_data.predict_proba(\n",
    "    [[-1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "print(\"The probability that Shaq beats Gray is {0}%\".format(round(result[0][0]*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have modeled the probaility that Shaq (-1) and Gray (-1) beat Rushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that Shaq and Gray beat Rushi is 100.0%\n"
     ]
    }
   ],
   "source": [
    "result = final_model_with_all_data.predict_proba(\n",
    "    [[-1, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]])\n",
    "print(\"The probability that Shaq and Gray beat Rushi is {0}%\".format(round(result[0][0]*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have modeled the probaility that Marc (-1) beats Sam (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that Marc beats Sam is 71.0%\n"
     ]
    }
   ],
   "source": [
    "result = final_model_with_all_data.predict_proba(\n",
    "    [[0, 0, 0, -1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "print(\"The probability that Marc beats Sam is {0}%\".format(round(result[0][0]*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have modeled the probaility that Marc (-1) and Sam (-1) beat Rushi (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that Marc and Sam beat Rushi is 28.75%\n"
     ]
    }
   ],
   "source": [
    "result = final_model_with_all_data.predict_proba(\n",
    "    [[0, 0, 1, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]])\n",
    "print(\"The probability that Marc and Sam beat Rushi is {0}%\".format(round(result[0][0]*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have modeled the probaility that Vic (-1) beats Rushi (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that Vic beats Rushi is 60.5%\n"
     ]
    }
   ],
   "source": [
    "result = final_model_with_all_data.predict_proba(\n",
    "    [[0, 0, 1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "print(\"The probability that Vic beats Rushi is {0}%\".format(round(result[0][0]*100, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
